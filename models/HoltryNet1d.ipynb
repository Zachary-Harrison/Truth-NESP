{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H7RH_vFs2Zv"
      },
      "source": [
        "# Import some packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnbU9mTUszSJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import time\n",
        "from copy import deepcopy\n",
        "\n",
        "device = 'cuda'\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch0JXJxIuOqT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb5R3is5s6E4"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "IHDDgYygs1hn",
        "outputId": "4389dd0e-4a80-4b93-f244-25639463a32e"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../data/kaggle/train.csv\")\n",
        "test_df = pd.read_csv(\"../data/kaggle/test.csv\")\n",
        "print(f\"Train dataframe has shape: {train_df.shape}\")\n",
        "print(f\"Test dataframe has shape: {test_df.shape}\")\n",
        "display(train_df.head())\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV_KtiL0y60d"
      },
      "source": [
        "# Transforming \n",
        "This will convert each protein sequence (a list of amino acids) to a matrix, where each row is the physical and chemical properties of the corresponding amino acid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GEs8Mkkxy7Ct",
        "outputId": "bb434401-67e7-44ab-8584-7c875e94470a"
      },
      "outputs": [],
      "source": [
        "df_aa = pd.read_csv(\"../data/aminoacids.csv\")\n",
        "\"\"\"\n",
        "0 = Name (Ignore)\n",
        "1 = Abbr (Ignore)\n",
        "2 = Letter\n",
        "3 = Molecular Weight\n",
        "4 = Molecular Formula\n",
        "5 = Residue Formula (Ignore)\n",
        "6 = Residue Weight (Ignore)\n",
        "7 = pKa1\n",
        "8 = pKb2\n",
        "9 = pKx3\n",
        "10 = pl4\n",
        "11 = H\n",
        "12 = VSC\n",
        "13 = P1\n",
        "14 = P2\n",
        "15 = SASA\n",
        "16 = NCISC\n",
        "17 = carbon\n",
        "18 = hydrogen\n",
        "19 = nitrogen\n",
        "20 = oxygen\n",
        "21 = sulfur\n",
        "\"\"\"\n",
        "feature_list = [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "df_aa = df_aa.fillna(method=\"bfill\")\n",
        "display(df_aa)\n",
        "df_aa.iloc[:, feature_list] = (df_aa.iloc[:, feature_list] - df_aa.iloc[:, feature_list].mean()) / df_aa.iloc[:, feature_list].std()\n",
        "display(df_aa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T69jmGGQ5gb"
      },
      "outputs": [],
      "source": [
        "# feature_list chooses which physical and chemical properties to inlcude\n",
        "def getTransformDict(feature_list = [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]):\n",
        "  transform_dict = {}\n",
        "  for index, row in df_aa.iterrows():\n",
        "    row_values = row.values\n",
        "    letter = row_values[2]\n",
        "    the_rest = [row_values[i] for i in feature_list]\n",
        "    transform_dict.update({letter: np.array(the_rest, dtype=\"float\")})\n",
        "  transform_dict.update({None: np.zeros(shape=len(feature_list),dtype=\"float\")})\n",
        "  return transform_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequences_train = [list(string) for string in train_df[\"protein_sequence\"].values.tolist()]\n",
        "lst = []\n",
        "transform_dict = getTransformDict()\n",
        "for sequence in sequences_train:\n",
        "    letterList = []\n",
        "    for letter in sequence:\n",
        "        letterList += transform_dict[letter].tolist()\n",
        "    lst.append(letterList)\n",
        "print(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC_WsPAOj6Fx"
      },
      "outputs": [],
      "source": [
        "# convert list of amino acids into a matrix of their corresponding physical and chemical properties\n",
        "def convertSequences(sequences, MAX_LENGTH, transform_dict=None):\n",
        "    if transform_dict is None:\n",
        "        transform_dict = getTransformDict()\n",
        "    sequenceList = []\n",
        "    for sequence in sequences:\n",
        "        letterMatrix = []\n",
        "        for i in range(MAX_LENGTH):\n",
        "            if i < len(sequence):\n",
        "                letterMatrix += transform_dict[sequence[i]].tolist()\n",
        "            else:\n",
        "                letterMatrix += transform_dict[None].tolist()\n",
        "        sequenceList.append(letterMatrix)\n",
        "    print(np.array(sequenceList))\n",
        "    return np.array(sequenceList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S__uwGT1SXxZ"
      },
      "outputs": [],
      "source": [
        "def getSequences(df, MAX_LENGTH=224):\n",
        "  df.reset_index(inplace=True)\n",
        "  sequences = [list(string) for string in df[\"protein_sequence\"].values.tolist()]\n",
        "  return convertSequences(sequences, MAX_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filterDataFrame(df, MIN_LENGTH=100, MAX_LENGTH=224):\n",
        "    df[\"protein_sequence_len\"] = df[\"protein_sequence\"].apply(lambda x: len(x))\n",
        "    df = df[df[\"protein_sequence_len\"] <= MAX_LENGTH]\n",
        "    df = df[df[\"protein_sequence_len\"] >= MIN_LENGTH]\n",
        "    if 'tm' in df:\n",
        "        df['tm'] = (df['tm'] - df['tm'].mean())/df['tm'].std()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KwLOvwnSYeB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MAX_LENGTH = 224\n",
        "MIN_LENGTH = 100\n",
        "train_df = filterDataFrame(train_df, MIN_LENGTH=MIN_LENGTH, MAX_LENGTH=MAX_LENGTH)\n",
        "X = getSequences(train_df, MAX_LENGTH=MAX_LENGTH)\n",
        "y = train_df['tm'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjf8H6oIzIBf"
      },
      "outputs": [],
      "source": [
        "test_df = filterDataFrame(test_df, MIN_LENGTH=MIN_LENGTH, MAX_LENGTH=MAX_LENGTH)\n",
        "X_test = getSequences(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXeUyLLbvu1X"
      },
      "source": [
        "## Loading and normalizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def toTensor(array):\n",
        "    return torch.Tensor(np.array(array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "437QWKVNvxA0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "print(torch.Tensor(np.array(X_train)))\n",
        "\n",
        "trainset = TensorDataset(toTensor(X_train), torch.Tensor(y_train))\n",
        "valset = TensorDataset(toTensor(X_val), torch.Tensor(y_val))\n",
        "testset = TensorDataset(toTensor(X_test))\n",
        "\n",
        "#TODO: revise batch_size\n",
        "BATCH_SIZE = 32\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDp5bMaOEW2b"
      },
      "source": [
        "# Using API Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG4bblfdDNro"
      },
      "outputs": [],
      "source": [
        "def make_prediction(model, file):\n",
        "    print(f'Saving results to {file}')\n",
        "    submission = pd.DataFrame()\n",
        "    submission[\"seq_id\"] = test_df[\"seq_id\"]\n",
        "    submission[\"tm\"] = model.predict(X_test)\n",
        "    submission.to_csv(file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jtwUM0XDGWb"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LinearRegression, SGDRegressor, LogisticRegression\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHakEyKYCHwT",
        "outputId": "bef0106d-ce63-4319-9816-0e625120e966"
      },
      "outputs": [],
      "source": [
        "# make_prediction(DecisionTreeRegressor().fit(X_train, y_train), 'DTRpred.csv')\n",
        "# make_prediction(RandomForestRegressor().fit(X_train, y_train), 'RFRpred.csv')\n",
        "# make_prediction(AdaBoostRegressor().fit(X_train, y_train), 'ABRpred.csv')\n",
        "# make_prediction(GradientBoostingRegressor().fit(X_train, y_train), 'GBRpred.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RtJFoa1vatc"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS7FzyrY7gDt"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfIOfsg68Ij_",
        "outputId": "8fecb47a-1605-49c6-be93-317ac6105b46"
      },
      "outputs": [],
      "source": [
        "model = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGWMpcv_uJ6K"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13NHIdD_l3TY"
      },
      "source": [
        "# Define the Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "B_na7Z2ivUnN",
        "outputId": "232f4792-d207-4cd3-8c12-7990b6c2b35f"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "best_val_loss = 100000\n",
        "best_val_model = None\n",
        "MAX_EPOCH = 30\n",
        "loss_record = {'train': [], 'dev': []} # added\n",
        "for epoch in range(MAX_EPOCH):  \n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.view(outputs.size(dim=0))\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_train_loss += loss.item()\n",
        "        out = outputs.detach()\n",
        "        assert out.shape == labels.shape\n",
        "        \n",
        "    loss_record['train'].append(running_train_loss/len(trainset))\n",
        "    \n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in valloader:\n",
        "            out = model(inputs.cuda()).cpu()\n",
        "            out = out.detach().view(out.size(dim=0))\n",
        "            running_val_loss += (torch.pow(out - labels, 2).sum().item()) ** 0.5\n",
        "    loss_record['dev'].append(running_val_loss/len(valset))\n",
        "    print(\"Epoch [{:>2} / {}]: Train loss = {:<25} Val Loss = {:<25}\".format(epoch+1, MAX_EPOCH, running_train_loss/len(trainset), running_val_loss/len(valset)))\n",
        "    if running_val_loss < best_val_loss:\n",
        "        best_val_loss = running_val_loss\n",
        "        best_val_model = deepcopy(model.state_dict())\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_learning_curve(record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    x_1 = range(len(record['train']))\n",
        "    x_2 = range(len(record['dev']))\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, record['dev'], c='tab:cyan', label='dev')\n",
        "    \n",
        "    # TODO: feel free to change this range to see the learning curve better\n",
        "    y_min = min(min(record['train']), min(record['dev']))\n",
        "    y_max = max(max(record['train']), max(record['dev']))\n",
        "    plt.ylim(max(.95*y_min-0.01, 0), 1.05*y_max+0.01)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_learning_curve(loss_record, title=\"CNN model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "aF9S5RIglvW2",
        "outputId": "41b19e98-d016-4a41-8f27-3a34ceddd528"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "preds = []\n",
        "model.load_state_dict(best_val_model)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs,labels in testloader:\n",
        "        out = model(inputs.cuda()).cpu()\n",
        "        out = torch.argmax(out,dim=1)\n",
        "        preds.append(out.detach().cpu())\n",
        "preds = torch.cat(preds, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_prediction(preds, file):\n",
        "    print(f'Saving results to {file}')\n",
        "    submission = pd.DataFrame()\n",
        "    submission[\"tm\"] = preds\n",
        "    submission[\"seq_id\"] = test_df[\"seq_id\"]\n",
        "    submission.to_csv(file, index=False)\n",
        "\n",
        "make_prediction(preds, file=\"pred.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b70492cf92a1f78fc18b7684d71bbc4f8886ffb7e78a5e47686b46a1a93e069b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
